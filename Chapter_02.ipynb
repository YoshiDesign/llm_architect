{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f053245-fece-4a56-92d4-96cdc4396522",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- Tiktokenizer\n",
    "- Excalidraw\n",
    "- Andrej Karpathy (Youtube) https://www.youtube.com/watch?v=7xTGNNLPyMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2a65d-f3e7-4774-a8ea-94319e849492",
   "metadata": {},
   "source": [
    "### My Notes\n",
    "- In this Notebook we're using Facebook's Open Pretrained Transformer (OPT)\n",
    "- The `tokenizer` object loads the vocabulary required to interact with the model and converts the sample input (`inp` variable) to token IDs and attention mask\n",
    "- The **attention mask** is a vector designed to help ignore specific tokens. (All 1's in this example, meaning we're not omitting anything)\n",
    "- We use `print(OPT_model.model)` to inspect the model's architecture. You'll notice `OPTDecoder` in the output, referring to the **Decoder** Only model\n",
    "- `return_tensors=\"pt\"` in our tokenizer() instantiation means we want our tokens returned as PyTorch Tensors, not NumPy arrays (default)\n",
    "- Use `nvidia-smi` to check your VRAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b0b8d0-359e-4ac1-8d70-f856be89fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./venv/lib/python3.11/site-packages (4.50.0)\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: bitsandbytes in ./venv/lib/python3.11/site-packages (0.45.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./venv/lib/python3.11/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./venv/lib/python3.11/site-packages (from accelerate) (2.6.0+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.2.0 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7599c6-5c13-456f-b9ef-0f8c21e78e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_name = \"facebook/opt-1.3b\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define quantization config -- This enables efficient utilization on consumer GPUs\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677c6cd-66a2-41d3-9949-9ba3ee3d4b59",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894ed3e-3d5e-4164-956b-3b3afca0a6ff",
   "metadata": {},
   "source": [
    "Note that the `.to()` method is applied to both the Model and the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4b5ea9-9200-4f59-92d6-d9e6c23051fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "OPT_model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, low_cpu_mem_usage=True)\n",
    "OPT_model.to(device) # Model is on the GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22a0abc-ae26-43ee-8748-7eac445491f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "{'input_ids': tensor([[    2,   133,  2119,  6219, 23602, 13855,    81,     5, 22414,  2335]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "inp = \"The quick brown fox jumps over the lazy dog\"\n",
    "inp_tokenized = tokenizer( inp, return_tensors=\"pt\" ).to(device) # Tokenizer is on the GPU\n",
    "\n",
    "print( inp_tokenized['input_ids'].size() )\n",
    "print( inp_tokenized )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250aff6f-3db7-4bd0-9db4-652ea880ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTModel(\n",
      "  (decoder): OPTDecoder(\n",
      "    (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
      "    (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
      "    (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x OPTDecoderLayer(\n",
      "        (self_attn): OPTSdpaAttention(\n",
      "          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (out_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "        )\n",
      "        (activation_fn): ReLU()\n",
      "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear4bit(in_features=2048, out_features=8192, bias=True)\n",
      "        (fc2): Linear4bit(in_features=8192, out_features=2048, bias=True)\n",
      "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( OPT_model.model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2cc05a-9dc6-4094-b3ca-8d75504cff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:\t Embedding(50272, 2048, padding_idx=1)\n",
      "Size:\t torch.Size([1, 10, 2048])\n",
      "Output:\t tensor([[[-0.0407,  0.0519,  0.0574,  ..., -0.0263, -0.0355, -0.0260],\n",
      "         [-0.0371,  0.0220, -0.0096,  ...,  0.0265, -0.0166, -0.0030],\n",
      "         [-0.0455, -0.0236, -0.0121,  ...,  0.0043, -0.0166,  0.0193],\n",
      "         ...,\n",
      "         [ 0.0007,  0.0267,  0.0257,  ...,  0.0622,  0.0421,  0.0279],\n",
      "         [-0.0126,  0.0347, -0.0352,  ..., -0.0393, -0.0396, -0.0102],\n",
      "         [-0.0115,  0.0319,  0.0274,  ..., -0.0472, -0.0059,  0.0341]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedded_input = OPT_model.model.decoder.embed_tokens(inp_tokenized['input_ids'])\n",
    "print( \"Layer:\\t\", OPT_model.model.decoder.embed_tokens )\n",
    "print( \"Size:\\t\", embedded_input.size() )\n",
    "print( \"Output:\\t\", embedded_input )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed1dd6-c9a7-4839-9eb3-4297ec97ce92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
